# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T0W9atQz5vMnfGaweEemfiZOF8fUxpGs
"""

from google.colab import drive
drive.mount('/content/drive')
!unzip "/content/drive/MyDrive/faceRecognitionp_project/Comys_Hackathon5.zip" -d "/content/drive/MyDrive/faceRecognitionp_project/"

import os
from torch.utils.data import Dataset,DataLoader
from PIL import Image
import torch
import torch.nn as nn
from torchvision import models,transforms
import torch.optim as optim

device=torch.device("cuda" if torch.cuda.is_available() else "cpu")





transform=transforms.Compose([
          transforms.Resize((224,224)),
          transforms.ToTensor(),
          transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])
      ])

class GenderClass(Dataset):
    def __init__(self,root_dir,transform=None):
        self.image_paths=[]
        self.labels=[]
        self.transform=transform
        for gender in ['male','female']:
            gender_folder=os.path.join(root_dir,gender)

            for filename in os.listdir(gender_folder):
                self.image_paths.append(os.path.join(gender_folder,filename))
                if gender=='male':
                    self.labels.append(0)
                else:
                    self.labels.append(1)

    def __len__(self):
        return len(self.image_paths)
    def __getitem__(self,idx):
        image_path=self.image_paths[idx]
        label=self.labels[idx]
        image=Image.open(image_path).convert('RGB')
        if self.transform:
            image=self.transform(image)
        return image,torch.tensor(label)


train_val="/content/drive/MyDrive/faceRecognitionp_project/Comys_Hackathon5/Task_A/train"
vali_val="/content/drive/MyDrive/faceRecognitionp_project/Comys_Hackathon5/Task_A/val"




vali_dataset=GenderClass(root_dir=vali_val,transform=transform)
vali_dataloader=DataLoader(vali_dataset,batch_size=8,shuffle=False)


train_dataset=GenderClass(root_dir=train_val,transform=transform)
train_dataloader=DataLoader(train_dataset,batch_size=8,shuffle=True)

model=models.resnet18(pretrained=True)
for params in model.parameters():
    params.requires_grad=False
model.fc=nn.Sequential(
    nn.Linear(512,512),
    nn.ReLU(), # Corrected typo: ReLu to ReLU
    nn.Dropout(0.3), # Corrected typo: 0,3 to 0.3
    nn.Linear(512,2)
     )
model = model.to(device)




criterion=nn.CrossEntropyLoss()
optimizer=optim.Adam(model.fc.parameters(),lr=0.001) # Corrected typo: Ir to lr
epochs=5
for ep in range(epochs):
    model.train()

    for image,label in train_dataloader:
        image,label=image.to(device),label.to(device)


        output=model(image)
        loss=criterion(output,label)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

model.eval()
counter=0
total=0
with torch.no_grad():
    for image,label in vali_dataloader:
        image,label=image.to(device),label.to(device)

        outputs=model(image)
        _,predicted=torch.max(outputs.data,1)
        total+=label.size(0) # Corrected typo: Size to size
        counter+=(predicted==label).sum().item()

val_acc = 100 * counter / total
print(f"Validation Accuracy: {val_acc:.2f}%")

# üî• 1Ô∏è‚É£1Ô∏è‚É£ SAVE MODEL

torch.save(model.state_dict(), "gender_classification_model.pth")
from google.colab import files
files.download("gender_classification_model.pth")
print("Model saved successfully!")

